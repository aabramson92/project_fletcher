{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/alexy161/Downloads/Headlines.txt', sep='@')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "import string\n",
    "\n",
    "alphanumeric = lambda x: re.sub(r\"\"\"\\w*\\d\\w*\"\"\", ' ', x)\n",
    "punc_lower = lambda x: re.sub('[%s]' % re.escape(string.punctuation), ' ', x.lower())\n",
    "stemmer = nltk.stem.LancasterStemmer()\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "\n",
    "df.article = df.article.map(alphanumeric).map(punc_lower)\n",
    "df.article = df.article.apply(nltk.word_tokenize)\n",
    "df.article = df.article.apply(lambda x: [word for word in x if word not in stop_words])\n",
    "df.article = df.article.apply(lambda x: [(stemmer.stem(word)) for word in x])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "df['article_words'] = df['article'].apply(lambda x: ' '.join(map(str, x)))\n",
    "x = df.article_words\n",
    "cv1 = CountVectorizer(stop_words='english')\n",
    "df_cv = cv1.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(df_cv.toarray(), columns=cv1.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "df['sentiment'] = ''\n",
    "df['sentiment'] = df.article_words.apply(lambda x: pd.Series(TextBlob(x).sentiment))\n",
    "df['positive'] = np.where(df['sentiment'] > 0, 1, 0)\n",
    "df['negative'] = np.where(df['sentiment'] < 0, 1, 0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfa = df.groupby('stock').mean().reset_index()\n",
    "dfa.sort_values(by='sentiment', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = pd.read_csv('/Users/alexy161/Downloads/Stock Revenues.csv')\n",
    "st = st[['stock', 'q2', 'q1']]\n",
    "st['q2_change'] = (st['q2'] - st['q1']) / st['q1']\n",
    "st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.merge(st, dfa, on='stock')\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "X = df1[['q2_change', 'sentiment', 'positive', 'negative']]\n",
    "stand = StandardScaler()\n",
    "X = stand.fit_transform(X)\n",
    "reducer = PCA(n_components=2)\n",
    "X = reducer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df1.q2_change, df1.sentiment)\n",
    "plt.title('Change in Sales and Headline Sentiment')\n",
    "plt.xlabel('Q2 Sales Change')\n",
    "plt.ylabel('Headline Sentiment');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_clusters = 5\n",
    "km = KMeans(n_clusters=num_clusters,init='k-means++',n_init=10)\n",
    "km.fit(X)\n",
    "c_label = km.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df1.q2_change, df1.sentiment, c=c_label)\n",
    "plt.title('Clusters for Change in Sales and Headline Sentiment')\n",
    "plt.xlabel('Q2 Sales Change')\n",
    "plt.ylabel('Headline Sentiment');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inertia = []\n",
    "list_num_clusters = list(range(1,10))\n",
    "for num_clusters in list_num_clusters:\n",
    "    km = KMeans(n_clusters=num_clusters)\n",
    "    km.fit(X)\n",
    "    inertia.append(km.inertia_)\n",
    "    \n",
    "plt.plot(list_num_clusters,inertia)\n",
    "plt.scatter(list_num_clusters,inertia)\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('Inertia');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, c_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df1.q2_change, df1.positive, c=c_label)\n",
    "plt.title('Clusters for Change in Sales and Positive Headline Frequency')\n",
    "plt.xlabel('Q2 Sales Change')\n",
    "plt.ylabel('Positive Headline Frequency');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df1.q2_change, df1.negative, c=c_label)\n",
    "plt.xlabel('Q2 Change')\n",
    "plt.ylabel('Negative');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
